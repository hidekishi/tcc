\chapter{Conclusão}

Nesse trabalho, foi possível investigar uma diversidade de aplicações paralelas em OpenMP e analisar suas características para no fim obter um modelo analítico de escalabilidade nesses contextos.

Os experimentos revelaram três padrões distintos de comportamento que dependem fundamentalmente das características das aplicações.

Aplicações altamente paralelas e com pouca interdependência (c\_mandel, c\_md) demonstraram excelente escalabilidade com eficiências superiores a 87\% e speedups próximos a 19× (24 \textit{threads}). A ausência de dependências entre iterações resultou em \textit{overhead} mínimo ($\phi < 0.5$). O escalonamento progressivo do problema evidenciou ganhos consistentes: c\_mandel aumentou eficiência de 72.3\% para 94.6\% entre problemas \textit{small} e \textit{extreme}, demonstrando que o volume de trabalho dilui o impacto de custos fixos de sincronização.

Aplicações com dependências moderadas (c\_pi, c\_fft6) apresentaram escalabilidade limitada com saturação entre 8-16 \textit{threads}. O \textit{overhead} de coordenação ($\phi = 3-4$) consumiu 3-4× o tempo serial, estabelecendo limites práticos mesmo quando o paralelismo teórico permitiria mais \textit{threads}. c\_fft6 atingiu speedup de 3.89×, próximo ao limite previsto pela fração serial de $\epsilon = 0.2534$.

Aplicações recursivas com alto \textit{overhead} (c\_fft, c\_qsort) mostraram paralelização contraproducente, com o custo de gerenciamento de \textit{tasks} ($\phi > 10$) superando consideravelmente os ganhos computacionais da paralelização. c\_qsort apresentou $\epsilon = 1.5569 > 1$, indicando que $T_p > T_1/p$, invalidando a métrica de Karp-Flatt torna-se inadequada devido ao \textit{overhead} dominar completamente o tempo de execução.

O \textbf{\textit{overhead}} mostrou-se como o principal fator limitante. Aplicações com $\phi < 0.5$ (c\_mandel, c\_md) escalaram até 24 \textit{threads} mantendo eficiência maior que 75\%, enquanto $\phi = 3-4$ (c\_pi, c\_fft6) limitaram-se a 8-16 \textit{threads}. Para $\phi > 10$ (c\_fft, c\_qsort), a paralelização tornou-se contraproducente, com o tempo de coordenação superando dramaticamente os ganhos computacionais.

Foi possível observar em partes a influência da arquitetura heterogênea, porém não se concluiu que ela foi relevante o suficiente para afetar consideravelmente os resultados de maneira geral muito por conta do comportamento aparente tomado pelo escalonador do sistema operacional. Nesse contexto, um fenômeno observado foi o de speedup superlinear no caso do c\_pi, que mostrou o impacto que o aproveitamento de cache pode ter em determinadas situações, potencialmente em decorrência de mais cache disponível nos P-\textit{cores}.

O modelo proposto $Es = E \cdot (1 - \phi/\max(\phi))$ apresentou correlação forte (Pearson $r = 0.89$) com limites de escalabilidade. Aplicações com $Es > 0.6$ (c\_mandel: 0.775, c\_md: 0.622) escalaram além de 16 \textit{threads}, enquanto $Es < 0.3$ (c\_fft6: 0.297, c\_qsort: 0.000) saturaram precocemente. A faixa intermediária $0.3 < Es < 0.6$ (c\_pi: 0.565) indicou saturação moderada entre 8-16 \textit{threads}.

Este estudo possui limitações que apontam direções para pesquisas futuras. Os experimentos utilizaram apenas núcleos físicos com \textit{Hyper-Threading} desabilitado, limitando a análise do impacto de \textit{Simultaneous Multithreading} (SMT) na escalabilidade.

O escopo potencialmente limitado das aplicações clássicas pode ser um limitador para uma análise mais presa a aplicações de uso real. A ausência de métricas energéticas (GFLOPS/Watt, \textit{energy-delay product}) limitam o estudo de eficiência completo por apenas lidar com as métricas de desempenho.